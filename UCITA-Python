# USAGE
# python text_detection_video.py --east frozen_east_text_detection.pb

# import the necessary packages
import numpy as np
from imutils.video import VideoStream
from imutils.video import FPS
import argparse
import imutils
import time
import cv2
import pytesseract
from googletrans import Translator
import arabic_reshaper
from bidi.algorithm import get_display
from PIL import Image, ImageDraw, ImageFont

pytesseract.pytesseract.tesseract_cmd = 'C:\\Program Files\\Tesseract-OCR\\tesseract'
translator = Translator()

ap = argparse.ArgumentParser()
ap.add_argument("-v", "--video", type=str,
                help="path to optinal input video file")
ap.add_argument("-c", "--min-confidence", type=float, default=0.5,
                help="minimum probability required to inspect a region")
ap.add_argument("-w", "--width", type=int, default=640,
                help="resized image width (should be multiple of 32)")
ap.add_argument("-e", "--height", type=int, default=640,
                help="resized image height (should be multiple of 32)")
# ap.add_argument("-l", "--lang", default="eng",
#                 help="language that Tesseract will use when OCR'ing")
ap.add_argument("-p", "--psm", type=int, default=6,
                help="Tesseract PSM mode")
args = vars(ap.parse_args())

LangFrom = input('Translate from: ')
LangTo = input('Translate To: ')

ArrayLang = ['arabic', 'frensh', 'english']
indexLangFrom = ArrayLang.index(LangFrom)
indexLangTo = ArrayLang.index(LangTo)
ArrayOCR = ['ara', 'fra', 'eng']
ArrayText = ['ar', 'fr', 'en']
# if a video path was not supplied, grab the reference to the web cam
if not args.get("video", False):
    print("[INFO] starting video stream...")
    vs = VideoStream(src=0).start()
    time.sleep(1.0)

# otherwise, grab a reference to the video file
else:
    vs = cv2.VideoCapture(args["video"])

# start the FPS throughput estimator
fps = FPS().start()

# loop over frames from the video stream
while True:
    # grab the current frame, then handle if we are using a
    # VideoStream or VideoCapture object
    frame = vs.read()
    frame = frame[1] if args.get("video", False) else frame

    # check to see if we have reached the end of the stream
    if frame is None:
        break

    # resize the frame, maintaining the aspect ratio
    frame = imutils.resize(frame, width=1000)
    image = frame.copy()
    cv2.imshow("Video", image)

    key1 = cv2.waitKey(1) & 0xFF
    # if the `q` key was pressed, break from the loop
    if key1 == ord("q"):
        frame = vs.read()
        cv2.destroyAllWindows()

        # re-recognize the text from the frame
        img_raw = frame.copy()
        ROIs = cv2.selectROIs("Select Rois", img_raw)
        # print rectangle points of selected roi
        print(ROIs)
        # loop over every bounding box save in array "ROIs"
        for rect in ROIs:
            x1 = rect[0]
            y1 = rect[1]
            x2 = rect[2]
            y2 = rect[3]

            # crop roi from original image
            img_crop = img_raw[y1:y1 + y2, x1:x1 + x2]

            # # show cropped image
            cv2.destroyAllWindows()
            gray = cv2.cvtColor(img_crop, cv2.COLOR_BGR2GRAY)
            cv2.imshow('gray', gray)
            options = "-l {} --psm {}".format(ArrayOCR[indexLangFrom], args["psm"])
            text = pytesseract.image_to_string(gray, config=options)
            # show the original OCR'd text
            print("ORIGINAL")
            print("========")
            print(text)
            print("")
            textTranslate = translator.translate(text, src=ArrayText[indexLangFrom], dest=ArrayText[indexLangTo])
            print('Translation')
            print(f'source: {textTranslate.src}')
            print(f'Destination: {textTranslate.dest}')
            print(f'{textTranslate.text}')
            print("")
            cv2.rectangle(img_raw, (x1, y1), (x1 + x2, y1 + y2), (255, 0, 0), 2)
            if LangTo == 'arabic':
                reshaped_text = arabic_reshaper.reshape(textTranslate.text)
                text = get_display(reshaped_text)
                al = "right"
                font_path = "arial.ttf"
                font = ImageFont.truetype(font_path, 40)
                img_pil = Image.fromarray(img_raw)
                draw = ImageDraw.Draw(img_pil)
                draw.rectangle((x1, y1, x1 + x2, y1 + y2), fill=(173, 171, 170))
                draw.text((x1, y1), text, font=font, align=al, fill=(255, 0, 0))
                img_raw = np.array(img_pil)
            else:
                text = textTranslate.text
                al = "left"
                font_path = "arial.ttf"
                font = ImageFont.truetype(font_path, 40)
                img_pil = Image.fromarray(img_raw)
                draw = ImageDraw.Draw(img_pil)
                draw.rectangle((x1, y1, x1 + x2, y1 + y2), fill=(173, 171, 170))
                draw.text((x1, y1), text, font=font, align=al, fill=(255, 0, 0))
                img_raw = np.array(img_pil)

        cv2.imshow("Text Detection", img_raw)

        cv2.waitKey(0)
    key2 = cv2.waitKey(1) & 0xFF
    if key2 == ord("z"):
        break
cv2.destroyAllWindows()

# stop the timer and display FPS information
fps.stop()
print("[INFO] elasped time: {:.2f}".format(fps.elapsed()))
print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))

# if we are using a webcam, release the pointer
if not args.get("video", False):
    vs.stop()

# otherwise, release the file pointer
else:
    vs.release()

# close all windows
cv2.destroyAllWindows()
